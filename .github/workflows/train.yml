name: TrainAction

on:
  push:
    branches-ignore: 
      - 'main'
      - 'preview'

concurrency:
  group: training-queue
  cancel-in-progress: false

jobs:

  filter-changes:
    runs-on: ubuntu-latest
    outputs:
      docker_changed: ${{ steps.validate_docker.outputs.docker_changed }}
    steps:
      - uses: actions/checkout@v3
      - name: Check if Docker changed
        id: validate_docker
        uses: dorny/paths-filter@v2
        with:
          filters: |
            docker:
              - 'docker/training/**'

  train:
    needs: filter-changes
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3


      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Build and Push Docker Images
        uses: ./.github/actions/training/build-and-push
        with:
          ecr_registry: ${{ secrets.ECR_REGISTRY }}
          ecr_repository: ${{ secrets.ECR_REPOSITORY }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: ${{ secrets.AWS_REGION }}
          training_image: ${{ secrets.ECR_REPOSITORY }}:train-${{ github.sha }}
          pipeline_image: ${{ secrets.ECR_REPOSITORY }}:pipeline-${{ github.sha }}
      # ----------------------------------------------------------------
      # BUILD the pipeline container locally (optional), if you want to run 
      # it directly in this workflow. Alternatively, you can re-use the 
      # ECR push if your build-and-push action already handles pipeline logic.
      # ----------------------------------------------------------------
      # - name: Build pipeline container
      #   run: |
      #     docker build \
      #       -t pipeline-docker \
      #       -f docker/training/PipelineDockerfile \
      #       .


      - name: Log into Amazon ECR
        shell: bash
        run: |
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} \
          | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}


      # TODO: Use github secrets and environment variables instead of hardcoding
      # region, tracking server name, etc.
      # Start MLFlow Tracking Server
      # - name: Start MLFlow Tracking Server
      #   run: |
      #     aws sagemaker start-mlflow-tracking-server --tracking-server-name MLFlowTracking --region us-west-2

      # ----------------------------------------------------------------
      # RUN the pipeline container, passing environment variables for Sagemaker
      # ----------------------------------------------------------------
      - name: Run Sagemaker Pipeline Container
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          SAGE_MAKER_EXECUTION_ROLE: ${{ secrets.SAGE_MAKER_EXECUTION_ROLE }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ steps.configure-aws-credentials.outputs.aws_session_token }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MLFLOW_TRACKING_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
          GITHUB_SHA: ${{ github.sha }}
        run: |
          docker run --rm \
            -e S3_BUCKET \
            -e SAGE_MAKER_EXECUTION_ROLE \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e AWS_SESSION_TOKEN \
            -e AWS_REGION \
            -e MLFLOW_TRACKING_ARN \
            -e ECR_REGISTRY \
            -e ECR_REPOSITORY \
            -e GITHUB_SHA \
            ${{ secrets.ECR_REGISTRY }}/${{ secrets.ECR_REPOSITORY }}:pipeline-${{ github.sha }} \
            conda run -n pipeline-env python /opt/ml/code/pipeline.py


      # TODO: Use github secrets and environment variables instead of hardcoding
      # region, tracking server name, etc.
      # Start MLFlow Tracking Server
      # - name: Stop MLFlow Tracking Server
      #   run: |
      #     aws sagemaker stop-mlflow-tracking-server --tracking-server-name MLFlowTracking --region us-west-2

      # - name: Upload Run ID to S3
      #   run: |
      #     aws s3 cp /opt/ml/model/run_id.txt s3://${{ secrets.S3_BUCKET }}/run_ids/${{ github.sha }}_run_id.txts
