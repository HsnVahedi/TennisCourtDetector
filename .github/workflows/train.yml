name: TrainAction

on:
  push:
    branches: [ "*" ]  # All branches

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Build and Push Docker Images
        uses: ./.github/actions/build-and-push
        with:
          ecr_registry: ${{ secrets.ECR_REGISTRY }}
          ecr_repository: ${{ secrets.ECR_REPOSITORY }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: ${{ secrets.AWS_REGION }}

      # ----------------------------------------------------------------
      # BUILD the pipeline container locally (optional), if you want to run 
      # it directly in this workflow. Alternatively, you can re-use the 
      # ECR push if your build-and-push action already handles pipeline logic.
      # ----------------------------------------------------------------
      - name: Build pipeline container
        run: |
          docker build \
            -t pipeline-docker \
            -f docker/training/PipelineDockerfile \
            .

      # ----------------------------------------------------------------
      # RUN the pipeline container, passing environment variables for Sagemaker
      # ----------------------------------------------------------------
      - name: Run Sagemaker Pipeline Container
        env:
          DATA_VERSION: ${{ github.event.inputs.dataset-version || '1' }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          SAGE_MAKER_EXECUTION_ROLE: ${{ secrets.SAGE_MAKER_EXECUTION_ROLE }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MLFLOW_TRACKING_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
        # run: |
        #   docker run --rm \
        #     -e DATA_VERSION \
        #     -e S3_BUCKET \
        #     -e SAGE_MAKER_EXECUTION_ROLE \
        #     -e AWS_REGION \
        #     -e MLFLOW_TRACKING_ARN \
        #     pipeline-docker \
        #     python /opt/ml/code/pipeline.py
        run: |
          docker run --rm \
            -e DATA_VERSION \
            -e S3_BUCKET \
            -e SAGE_MAKER_EXECUTION_ROLE \
            -e AWS_REGION \
            -e MLFLOW_TRACKING_ARN \
            pipeline-docker \
            conda run -n pipeline-env python /opt/ml/code/pipeline.py
