name: TrainAction

on:
  push:
    branches-ignore: 
      - 'main'
      - 'preview'

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Build and Push Docker Images
        uses: ./.github/actions/training/build-and-push
        with:
          ecr_registry: ${{ secrets.ECR_REGISTRY }}
          ecr_repository: ${{ secrets.ECR_REPOSITORY }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: ${{ secrets.AWS_REGION }}
          training_image: ${{ secrets.ECR_REPOSITORY }}:train-${{ github.sha }}
          pipeline_image: ${{ secrets.ECR_REPOSITORY }}:pipeline-${{ github.sha }}
      # ----------------------------------------------------------------
      # BUILD the pipeline container locally (optional), if you want to run 
      # it directly in this workflow. Alternatively, you can re-use the 
      # ECR push if your build-and-push action already handles pipeline logic.
      # ----------------------------------------------------------------
      # - name: Build pipeline container
      #   run: |
      #     docker build \
      #       -t pipeline-docker \
      #       -f docker/training/PipelineDockerfile \
      #       .

      # ----------------------------------------------------------------
      # RUN the pipeline container, passing environment variables for Sagemaker
      # ----------------------------------------------------------------
      - name: Run Sagemaker Pipeline Container
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          SAGE_MAKER_EXECUTION_ROLE: ${{ secrets.SAGE_MAKER_EXECUTION_ROLE }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ steps.configure-aws-credentials.outputs.aws_session_token }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MLFLOW_TRACKING_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
          GITHUB_SHA: ${{ github.sha }}
        run: |
          docker run --rm \
            -e S3_BUCKET \
            -e SAGE_MAKER_EXECUTION_ROLE \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e AWS_SESSION_TOKEN \
            -e AWS_REGION \
            -e MLFLOW_TRACKING_ARN \
            -e ECR_REGISTRY \
            -e ECR_REPOSITORY \
            -e GITHUB_SHA \
            ${{ secrets.ECR_REPOSITORY }}:pipeline-${{ github.sha }} \
            conda run -n pipeline-env python /opt/ml/code/pipeline.py
