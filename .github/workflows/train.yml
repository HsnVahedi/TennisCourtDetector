name: TrainAction

on:
  push:
    branches-ignore: 
      - 'main'
      - 'preview'

concurrency:
  group: training-queue
  cancel-in-progress: false

jobs:

  build-and-push:
    runs-on: ubuntu-latest
    outputs:
      docker_changed: ${{ steps.validate_changes.outputs.docker }}
    steps:
      # - uses: actions/checkout@v3
      #   with:
      #     fetch-depth: 0  # fetch entire history so changes can be compared
      - name: Checkout Code
        uses: actions/checkout@v3  

      - name: Check if Docker changed
        id: validate_changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            docker:
              - 'docker/training/**'
      - name: Debug docker_changed value
        run: |
          echo "docker_changed value from filter-changes: ${{ steps.validate_changes.outputs.docker == 'true' }}"

      


      # - name: Configure AWS Credentials
      #   uses: aws-actions/configure-aws-credentials@v2
      #   with:
      #     aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     aws-region: ${{ secrets.AWS_REGION }}

      - name: Build and Push Docker Images
        
        uses: ./.github/actions/training/build-and-push
        with:
          ecr_registry: ${{ secrets.ECR_REGISTRY }}
          ecr_repository: ${{ secrets.ECR_REPOSITORY }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: ${{ secrets.AWS_REGION }}
          training_image: ${{ secrets.ECR_REPOSITORY }}/train
          pipeline_image: ${{ secrets.ECR_REPOSITORY }}/pipeline
          image_tag: ${{ github.sha }}
          docker_changed: ${{ steps.validate_changes.outputs.docker == 'true' }}

  check-mlflow-server:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      

      - name: Check and start MLflow server if not active
        shell: bash
        env:
          SERVER_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
        run: |
          set -e

          COUNTER=0
          MAX_RETRIES=10
          TRACKING_SERVER_NAME="MLFlowTracking"

          while [ $COUNTER -lt $MAX_RETRIES ]; do
            echo "Listing MLflow tracking servers..."
            OUTPUT=$(aws sagemaker list-mlflow-tracking-servers --region ${{ secrets.AWS_REGION }})

            # Extract the 'IsActive' status for the desired server ARN
            IS_ACTIVE=$(echo "$OUTPUT" | jq -r ".TrackingServerSummaries[] | select(.TrackingServerArn==\"${SERVER_ARN}\") | .IsActive")

            if [ "$IS_ACTIVE" == "Active" ]; then
              echo "MLflow server is already active."
              break
            else
              echo "MLflow server not active. Attempting to start it..."
              aws sagemaker start-mlflow-tracking-server --tracking-server-name "$TRACKING_SERVER_NAME" --region ${{ secrets.AWS_REGION }}
            fi

            COUNTER=$((COUNTER+1))
            echo "Waiting for 30 seconds before checking again..."
            sleep 30
          done

          if [ "$IS_ACTIVE" != "Active" ]; then
            echo "MLflow server did not become active in time (${MAX_RETRIES} checks)."
            exit 1
          fi

  train:
    needs: [build-and-push, check-mlflow-server]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3


      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Log into Amazon ECR
        shell: bash
        run: |
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} \
          | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}


      - name: Run Sagemaker Pipeline Container
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          SAGE_MAKER_EXECUTION_ROLE: ${{ secrets.SAGE_MAKER_EXECUTION_ROLE }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ steps.configure-aws-credentials.outputs.aws_session_token }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MLFLOW_TRACKING_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
          GITHUB_SHA: ${{ github.sha }}
        run: |
          docker run --rm \
            -e S3_BUCKET \
            -e SAGE_MAKER_EXECUTION_ROLE \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e AWS_SESSION_TOKEN \
            -e AWS_REGION \
            -e MLFLOW_TRACKING_ARN \
            -e ECR_REGISTRY \
            -e ECR_REPOSITORY \
            -e GITHUB_SHA \
            ${{ secrets.ECR_REGISTRY }}/${{ secrets.ECR_REPOSITORY }}/pipeline:latest \
            conda run -n pipeline-env python /opt/ml/code/pipeline.py



